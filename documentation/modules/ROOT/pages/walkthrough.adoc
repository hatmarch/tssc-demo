= Walkthrough
include::_attributes.adoc[]

[#platform]
== Secure Software Factory Platform

. Log into the OpenShift platform with a cluster admin and open two tabs (or windows):
+
[tabs]
====
Admin Perspective::
+
--
Open the *Admin Perspective* of the dashboard (possibly initialized to the `devsecops` project):

image::initial-admin-view.png[]

--
Developer Perspective (Topology View)::
+
--
[#topologyview]
Open the *Topology View* of the `devsecops` project, as seen here:

image::initial-topology-view.png[]

--
====
+
. Switch to the `devsecops` project and click on OperatorHub
. Scroll down to provider type and check `Red Hat NAPS Community Operators`.  Type `software factory` to attract focus on the Ploigos operator
** Explain that OpenShift allows administers to subscribe to different channels (even their own trusted internal channels) for available operators
** This represents Red Hat consulting's catalog of trusted operators
+
image::operator-catalog.png[]
+
. Next let's take a look at the (pre) installed Software Factory Operator in more detail.  Click on the `Installed Operators` button in the left navbar.  Click on the Ploigos Software Factory Operator
+
image::installed-operators.png[]
+
. Scroll through the Operator Details page and double check that the operator is successfully installed.  
. Point out the two different CustomResources that the operator watches for, namely the `TsscPipeline` and `TsscPlatform` CRs.  
. Select the `TsscPlatform` CR to create the platform for our secure software factory.  Click the `Create TsscPlatform` button
+
image::tsscplatform.png[]
+
. Switch to the YAML view and briefly show the different configuration options for the platform and then click `Create`
+
image::tsscplatform-detail.png[]
+
. As soon as you hit create, switch to the second tab/window <<topologyview,*Developer Perspective (Topology View)*>>
+
. Zoom out to show the operator doing its work to create the items in the platform.  Here's what it looks like in the middle of its run:
+
image::operator-buildout.png[]
+
. Wait for the platform to be built out
+
[NOTE]
.Determining when the platform is completed
====
You can determine when the operator has completed successfully by running the following command in a hidden terminal:

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
(cd pass:[${DEMO_HOME}]/ansible; ansible localhost -m include_role -a name=ploigos_support -e ploigos_wait=true -e ploigos_install=false)
----

If it completes successfully you should see something like this:
[.console-output]
[source,bash]
----
localhost | SUCCESS => {
    "msg": "Platform has been successfully installed"
}
----
====
+
. When the platform has finished, refit the Topology View if you haven't already and zoom out to survey the different aspects of the platform
+
image::dev-perspective-controls.png[]
+
. When the platform has finished, return to the operator <<topologyview,*Admin Perspective*>> and show that the platform has indicated successful installation
+
image::tsscplatform-successful.png[]
+
. OPTIONAL: Click into the yaml view of the admin perspective and compare it to the topology view as indicated below:
+
image::platform-compare.png[]

[#pipeline]
== Create and Examine (Jenkins) Pipeline

. Log into the openshift console and go to the `devsecops` project in Developer Perspective
+
[IMPORTANT]
====
If you need to customize the openSCAP checks against your repo, then **you must first do the following** before proceeding with the walkthrough:

. Update the default platform pipeline configuration to entirely rely on the config from the built project:
+
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc create configmap ploigos-platform-config \
    --from-file=config.yml=<(oc get cm/ploigos-platform-config -n devsecops -o jsonpath='{.data.config\.yml}' \
             | yq - d 'step-runner-config.container-image-static-compliance-scan' \
             | yq - d 'step-runner-config.container-image-static-vulnerability-scan') \
    --dry-run=client -o yaml | oc replace -n devsecops -f -
----
+
. Ensure that the project that you intend to build has configuration information for the (parallel) openSCAP steps.  For example:
+
image::app-config-openscap.png[]
====
+
. Zoom out to show the whole of the platform
+
image::platform-dev-view.png[]
+
. Click on `Search` and look for tsscpipeline
+
image::search-tssc.png[]
+
. Click Create TsscPipeline
. Fill in the pipeline with the contents of this 
+
[.console-input]
[source,yaml,subs="+macros,+attributes"]
----
include::example$tsscpipeline.yaml[]
----
+
. Click `Create` which will create the custom resource and the operator will begin setup
+
. Once the `TsscPipeline` resource is ready, then return to DevPerspective and search for Jenkins in the (zoomed out) devconsole
+
image::search-jenkins.png[]
+
. Click the route badge on the Jenkins instance to open the Jenkins master
. Login using your OpenShift Credentials
+
image::openshift-oauth-jenkins.png[]
+
. Once in the Jenkins console, click on Open Blue Ocean
+
image::jenkins-blue-ocean.png[]
+
. Select the pipeline (it should be in progress) and show the pipeline view of the running instance
+
image::jenkins-running-pipeline.png[]
+
. Let's show how our reference app interacted with this pipeline by opening the `Jenkinsfile` of the  reference app by using this link:
+
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
echo "http://$(oc get route gitea -n devsecops -o jsonpath='pass:[{.spec.host}]')/platform/{app_code_repo_name}/src/branch/main/cicd/Jenkinsfile"
----
+
[NOTE]
====
The login details for the internal git repo are

[.console-input]
[source,bash]
----
#USER
oc get secret gitea-admin-credentials -o jsonpath='{.data.username}' -n devsecops | base64 -d
echo ""
#PASSWORD
oc get secret gitea-admin-credentials -o jsonpath='{.data.password}' -n devsecops | base64 -d
----
====
+
. You should see something like the example below.  Make sure you draw a mapping between the stages of the Blue Ocean Pipeline and what's in this Jenkinsfile
+
image::Jenkinsfile.png[]
+
. Next show the config.yaml
+
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
echo "http://$(oc get route gitea -n devsecops -o jsonpath='pass:[{.spec.host}]')/platform/{app_code_repo_name}/src/branch/main/cicd/ploigos-step-runner-config/config.yml"
----
+
image::config-yaml.png[title="Notice rekor-server-url config for RekorLog substep"]
+
. Show that the Rekor server for this demo is running in cluster by switching to the {rekor_project} and looking at the topology view
+
image::rekor-topology.png[title="RekorLog is also publicly accessible"]
+ 
. Open up the log view on the rekor server and show that entries were logged
+
image::rekor-log-log.png[title="Two entries in RekorLog made by build chain"]
+
image:sign-image-stage.png[width=200,role=right] 
+
. Return to the Jenkins Blue Ocean tab and look at the logs for the `CI: Sign Trusted Container Image` stage
. Scroll down to the bottom of the logs and show the two rekor log events
+
image::rekorlog-jenkins-log.png[title="Two log events"]

[#rekor]
== Review Rekor Logs

In this section we look at what was logged to Rekor and how it relates to the Jenkins pipeline build from the previous section

_Coming Soon_
